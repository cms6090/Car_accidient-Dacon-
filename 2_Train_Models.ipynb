{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752c5fb2",
   "metadata": {},
   "source": [
    "- 목적: 1번 노트북이 저장한 Feather를 불러와 모델 학습/보정만 수행\n",
    "- [수정] Data Leakage를 완벽히 수정한 K-Fold 로직 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d6b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big-Tech ML Engineer: K-Fold + Leakage Fix + Domain Features 최종 전략 시작.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import catboost as cb # 대부분이 범주형변수로 이루어진 데이터셋에서 예측 성능이 우수 => 범주형 변수를 one-hot encoding 등 encoding 작업을 하지 않고 그대로 모델의 input, 알아서 target encoding 해줌\n",
    "from sklearn.model_selection import StratifiedKFold # 라벨 비율 유지하며 K-fold 분할\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, mean_squared_error\n",
    "from sklearn.calibration import calibration_curve \n",
    "from sklearn.isotonic import IsotonicRegression # 확률 보정용 : 타겟 함수가 단조 증가함수일때만 가능\n",
    "from tqdm import tqdm\n",
    "import joblib # 모델/보정기 저장\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Big-Tech ML Engineer: K-Fold + Leakage Fix + Domain Features 최종 전략 시작.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9252ae",
   "metadata": {},
   "source": [
    "## 1. 로컬 경로 설정 및 \"전처리된 데이터\" 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 메인 피처 로드 중... (매우 빠름)\n",
      "데이터 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"./data\"\n",
    "MODEL_SAVE_DIR = \"./model\" \n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True) # ./model 디렉토리 없으면 생성, exist_ok = True라 있어도 오류 X\n",
    "FEATURE_SAVE_PATH = os.path.join(BASE_DIR, \"all_train_data.feather\")\n",
    "\n",
    "try:\n",
    "    print(f\"전처리된 메인 피처 로드 중... (매우 빠름)\")\n",
    "    all_train_df = pd.read_feather(FEATURE_SAVE_PATH)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"경고: {e}\")\n",
    "    print(\"먼저 1_Preprocess.ipynb를 실행하여 all_train_data.feather를 생성해야 합니다.\")\n",
    "    raise\n",
    "print(\"데이터 로드 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Calibration Error(ECE) 계산기 (버그 수정됨) \n",
    "def expected_calibration_error(y_true, y_prob, n_bins=10): # y_true: 실제 라벨(0/1), y_prob: 예측 확률(0~1 ideally), n_bins: 몇 개 구간으로 나눠서 calibration을 볼지.\n",
    "    if len(y_true) == 0 or len(y_prob) == 0: return 0.0 # 데이터 없으면 ECE = 0\n",
    "    y_prob = np.nan_to_num(y_prob, nan=0.0) # nan을 전부 0.0으로 치환\n",
    "    \n",
    "    df = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob})\n",
    "    \n",
    "    bin_edges = np.linspace(0, 1, n_bins + 1) # 0~1 구간을 균등하게 n_bins개로 나누는 경계 생성.\n",
    "    bin_edges[0] = -0.001 # 경계 살짝 벌려서 0.0/1.0 같은 값이 pd.cut에서 누락되지 않도록.\n",
    "    bin_edges[-1] = 1.001 \n",
    "    \n",
    "    # pd.cut에서 NA가 발생하지 않도록 y_prob의 범위를 강제로 [0, 1]로 클리핑\n",
    "    df['y_prob'] = np.clip(df['y_prob'], 0, 1)\n",
    "    df['bin'] = pd.cut(df['y_prob'], bins=bin_edges, right=True) # 각 샘플을 예측 확률 기준으로 구간(bin)에 할당.\n",
    "    \n",
    "    # .groupby(..., observed=True) to handle potential empty bins\n",
    "    bin_stats = df.groupby('bin', observed=True).agg(\n",
    "        bin_total=('y_prob', 'count'), # 샘플 수\n",
    "        prob_true=('y_true', 'mean'), # 실제 양성 비율\n",
    "        prob_pred=('y_prob', 'mean') # 예측 확률 평균\n",
    "    )\n",
    "    \n",
    "    non_empty_bins = bin_stats[bin_stats['bin_total'] > 0] # 샘플이 없는 bin 제거\n",
    "    if len(non_empty_bins) == 0: return 0.0 # 전부 비어있으면 ECE = 0\n",
    "    \n",
    "    bin_weights = non_empty_bins['bin_total'] / len(y_prob) # 각 bin이 전체에서 차지하는 비율(가중치).\n",
    "    prob_true = non_empty_bins['prob_true']\n",
    "    prob_pred = non_empty_bins['prob_pred']\n",
    "    \n",
    "    ece = np.sum(bin_weights * np.abs(prob_true - prob_pred)) # ECE 정의 : Σ (bin_weight * |실제양성비 - 예측확률|)\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 점수 계산기\n",
    "def combined_score(y_true, y_prob): # AUC / Brier / ECE를 계산하고, 커스텀 스코어를 출력\n",
    "    if len(y_true) == 0 or len(y_prob) == 0 or np.sum(y_true) == 0 or np.sum(y_true) == len(y_true): \n",
    "        print(\"  AUC: N/A (단일 클래스), Brier: N/A, ECE: N/A (No data)\")\n",
    "        return 1.0 \n",
    "    # 데이터 없거나 모든 라벨이 0이거나 1인 경우(AUC 정의 안 됨) => \"최악\"으로 1.0 리턴 (이 스코어는 낮을수록 좋다는 설계이므로).\n",
    "    \n",
    "    y_prob = np.nan_to_num(y_prob, nan=0.0) # 다시 한 번 NaN 방지\n",
    "    \n",
    "    mean_auc = roc_auc_score(y_true, y_prob)\n",
    "    mean_brier = mean_squared_error(y_true, y_prob)\n",
    "    mean_ece = expected_calibration_error(y_true, y_prob) \n",
    "    score = 0.5 * (1 - mean_auc) + 0.25 * mean_brier + 0.25 * mean_ece # AUC는 클수록 좋으니 (1 - AUC). Brier / ECE는 작을수록 좋으니 그대로. 가중치 0.5 / 0.25 / 0.25.\n",
    "    print(f\"  AUC: {mean_auc:.4f}, Brier: {mean_brier:.4f}, ECE: {mean_ece:.4f}\")\n",
    "    print(f\"  Combined Score: {score:.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d5654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] K-Fold 교차 검증 분리 시작...\n",
      "5-Fold 분리 완료.\n"
     ]
    }
   ],
   "source": [
    "## 6. K-Fold 분리 (오류 수정)\n",
    "print(\"\\n[INFO] K-Fold 교차 검증 분리 시작...\")\n",
    "N_SPLITS = 5 # 5 교차 검증\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42) # Label 비율 유지 + 셔플 + 재현 가능한 분할\n",
    "\n",
    "# fold별 train/val 인덱스를 저장할 리스트.\n",
    "train_indices_list = []\n",
    "val_indices_list = []\n",
    "\n",
    "all_train_df['Label'] = all_train_df['Label'].fillna(0) # Label NaN 방지용\n",
    "\n",
    "# skf.split(X, y)는 각 fold마다 train/val 인덱스를 반환. 이를 리스트에 순서대로 저장\n",
    "for train_idx, val_idx in skf.split(all_train_df, all_train_df['Label']): \n",
    "    train_indices_list.append(train_idx)\n",
    "    val_indices_list.append(val_idx)\n",
    "\n",
    "print(f\"{N_SPLITS}-Fold 분리 완료.\")\n",
    "\n",
    "CAT_FEATURES = ['Age', 'PrimaryKey'] # CatBoost에 “범주형으로 처리할 컬럼” 목록.\n",
    "\n",
    "# [수정] 'Test' -> 'Test_x' (1_Preprocess에서 병합 시 생성된 이름)\n",
    "DROP_COLS_TRAIN = ['Test_id', 'Test_x', 'Test_y', 'Label', 'TestDate', 'Year', 'Month', 'base_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Model A (CatBoost Only) - [수정] PK Stats 제거\n",
    "def train_model_A(X_train, y_train, X_val, y_val, group_label=\"A\"):\n",
    "    \n",
    "    # 피처 정의 (PK Stats 관련 피처 제외)\n",
    "    base_cols = [col for col in X_train.columns if not col.startswith('pk_')] # X_train에 pk_ 통계 컬럼이 들어와도 사용하지 않도록 필터링\n",
    "    numeric_cols = list(set(base_cols) - set(CAT_FEATURES) - set(DROP_COLS_TRAIN))\n",
    "    \n",
    "    cb_X_train = X_train[numeric_cols + CAT_FEATURES]\n",
    "    cb_X_val = X_val[numeric_cols + CAT_FEATURES]\n",
    "    \n",
    "    for col in CAT_FEATURES:\n",
    "        cb_X_train[col] = cb_X_train[col].fillna('nan').astype(str)\n",
    "        cb_X_val[col] = cb_X_val[col].fillna('nan').astype(str)\n",
    "        \n",
    "    cat_features_indices = [cb_X_train.columns.get_loc(c) for c in CAT_FEATURES if c in cb_X_train] # CatBoost는 cat_features에 “컬럼 인덱스”를 넣어야 하므로 위치 계산\n",
    "    \n",
    "    print(f\"\\n[{group_label}] CatBoost (Base) 학습 시작... (피처 {len(cb_X_train.columns)}개)\")\n",
    "    cat_base_model = cb.CatBoostClassifier(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.05, \n",
    "        depth=6, \n",
    "        l2_leaf_reg=3, \n",
    "        loss_function='Logloss', \n",
    "        eval_metric='AUC', # eval_metric='AUC': 검증 기준 AUC\n",
    "        random_seed=42,\n",
    "        thread_count=-1,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose=1000,\n",
    "        task_type='GPU'\n",
    "    )\n",
    "    cat_base_model.fit(\n",
    "        cb_X_train, y_train,\n",
    "        eval_set=[(cb_X_val, y_val)],\n",
    "        cat_features=cat_features_indices # cat_features_indices로 범주형 컬럼 지정.\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[{group_label}] 단독 확률 보정 (Isotonic) 시작...\")\n",
    "    pred_cat_uncal = cat_base_model.predict_proba(cb_X_val)[:,1]\n",
    "\n",
    "    print(f\"[{group_label}] 비보정 단독 점수:\") \n",
    "    _ = combined_score(y_val, pred_cat_uncal) # 보정 전 확률로 AUC/Brier/ECE 출력.\n",
    "    \n",
    "    # 단조 증가 형태로 raw_prob → calibrated_prob를 학습. out_of_bounds='clip': 학습 범위 밖 값은 양 끝으로 클리핑.\n",
    "    final_calibrator = IsotonicRegression(y_min=0, y_max=1, out_of_bounds='clip')\n",
    "    final_calibrator.fit(pred_cat_uncal, y_val) \n",
    "    \n",
    "    pred_cat_calibrated = final_calibrator.predict(pred_cat_uncal)\n",
    "    print(f\"[{group_label}] ★보정된 단독★ 최종 점수:\")\n",
    "    _ = combined_score(y_val, pred_cat_calibrated)\n",
    "    \n",
    "    return cat_base_model, final_calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Model B (CatBoost Only)\n",
    "def train_model_B(X_train, y_train, X_val, y_val, pk_stats_fold, group_label=\"B\"):\n",
    "    \n",
    "    # --- [Leakage 수정] PK Stats 병합 ---\n",
    "    X_train = X_train.merge(pk_stats_fold, on='PrimaryKey', how='left')\n",
    "    X_val = X_val.merge(pk_stats_fold, on='PrimaryKey', how='left')\n",
    "    \n",
    "    # --- 피처 정의 ---\n",
    "    numeric_cols = list(set(X_train.columns) - set(CAT_FEATURES) - set(DROP_COLS_TRAIN))\n",
    "    common_numeric_cols = list(set(X_train[numeric_cols].columns) & set(X_val[numeric_cols].columns))\n",
    "    \n",
    "    cb_X_train = X_train[common_numeric_cols + CAT_FEATURES]\n",
    "    cb_X_val = X_val[common_numeric_cols + CAT_FEATURES]\n",
    "    \n",
    "    for col in CAT_FEATURES:\n",
    "        cb_X_train[col] = cb_X_train[col].fillna('nan').astype(str)\n",
    "        cb_X_val[col] = cb_X_val[col].fillna('nan').astype(str)\n",
    "        \n",
    "    cat_features_indices = [cb_X_train.columns.get_loc(c) for c in CAT_FEATURES if c in cb_X_train]\n",
    "    \n",
    "    # --- CatBoost (Base) 학습 ---\n",
    "    print(f\"\\n[{group_label}] CatBoost (Base) 학습 시작... (피처 {len(cb_X_train.columns)}개)\")\n",
    "    cat_base_model = cb.CatBoostClassifier(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.05, \n",
    "        depth=6, \n",
    "        l2_leaf_reg=3, \n",
    "        loss_function='Logloss', \n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        thread_count=-1,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose=1000,\n",
    "        task_type='GPU'\n",
    "    )\n",
    "    cat_base_model.fit(\n",
    "        cb_X_train, y_train,\n",
    "        eval_set=[(cb_X_val, y_val)],\n",
    "        cat_features=cat_features_indices\n",
    "    )\n",
    "    \n",
    "    # --- 보정기 학습 ---\n",
    "    print(f\"\\n[{group_label}] 단독 확률 보정 (Isotonic) 시작...\")\n",
    "    pred_cat_uncal = cat_base_model.predict_proba(cb_X_val)[:,1]\n",
    "    print(f\"[{group_label}] 비보정 단독 점수:\")\n",
    "    _ = combined_score(y_val, pred_cat_uncal)\n",
    "    \n",
    "    final_calibrator = IsotonicRegression(y_min=0, y_max=1, out_of_bounds='clip')\n",
    "    final_calibrator.fit(pred_cat_uncal, y_val) \n",
    "    \n",
    "    pred_cat_calibrated = final_calibrator.predict(pred_cat_uncal)\n",
    "    print(f\"[{group_label}] ★보정된 단독★ 최종 점수:\")\n",
    "    _ = combined_score(y_val, pred_cat_calibrated)\n",
    "    \n",
    "    return cat_base_model, final_calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 학습 시작 ---\n",
      "\n",
      "[Fold 1] K-Fold Target Encoding (PK Stats) 생성...\n",
      "\n",
      "--- 모델 A (신규 자격) 학습 ---\n",
      "\n",
      "[A] CatBoost (Base) 학습 시작... (피처 98개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6355240\tbest: 0.6355240 (0)\ttotal: 57.1ms\tremaining: 2m 51s\n",
      "bestTest = 0.7062878311\n",
      "bestIteration = 862\n",
      "Shrink model to first 863 iterations.\n",
      "\n",
      "[A] 단독 확률 보정 (Isotonic) 시작...\n",
      "[A] 비보정 단독 점수:\n",
      "  AUC: 0.7063, Brier: 0.0202, ECE: 0.0008\n",
      "  Combined Score: 0.15210\n",
      "[A] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7087, Brier: 0.0200, ECE: 0.0000\n",
      "  Combined Score: 0.15065\n",
      "\n",
      "--- 모델 B (자격 유지) 학습 ---\n",
      "\n",
      "[B] CatBoost (Base) 학습 시작... (피처 126개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6144319\tbest: 0.6144319 (0)\ttotal: 18ms\tremaining: 53.9s\n",
      "bestTest = 0.7395755947\n",
      "bestIteration = 73\n",
      "Shrink model to first 74 iterations.\n",
      "\n",
      "[B] 단독 확률 보정 (Isotonic) 시작...\n",
      "[B] 비보정 단독 점수:\n",
      "  AUC: 0.7396, Brier: 0.0385, ECE: 0.0224\n",
      "  Combined Score: 0.14544\n",
      "[B] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7432, Brier: 0.0374, ECE: 0.0000\n",
      "  Combined Score: 0.13774\n",
      "\n",
      "--- Fold 2/5 학습 시작 ---\n",
      "\n",
      "[Fold 2] K-Fold Target Encoding (PK Stats) 생성...\n",
      "\n",
      "--- 모델 A (신규 자격) 학습 ---\n",
      "\n",
      "[A] CatBoost (Base) 학습 시작... (피처 98개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6365899\tbest: 0.6365899 (0)\ttotal: 20.7ms\tremaining: 1m 2s\n",
      "bestTest = 0.7065390944\n",
      "bestIteration = 247\n",
      "Shrink model to first 248 iterations.\n",
      "\n",
      "[A] 단독 확률 보정 (Isotonic) 시작...\n",
      "[A] 비보정 단독 점수:\n",
      "  AUC: 0.7065, Brier: 0.0203, ECE: 0.0008\n",
      "  Combined Score: 0.15200\n",
      "[A] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7085, Brier: 0.0201, ECE: 0.0000\n",
      "  Combined Score: 0.15080\n",
      "\n",
      "--- 모델 B (자격 유지) 학습 ---\n",
      "\n",
      "[B] CatBoost (Base) 학습 시작... (피처 126개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6127095\tbest: 0.6127095 (0)\ttotal: 16.7ms\tremaining: 50.2s\n",
      "bestTest = 0.7407455742\n",
      "bestIteration = 153\n",
      "Shrink model to first 154 iterations.\n",
      "\n",
      "[B] 단독 확률 보정 (Isotonic) 시작...\n",
      "[B] 비보정 단독 점수:\n",
      "  AUC: 0.7407, Brier: 0.0378, ECE: 0.0137\n",
      "  Combined Score: 0.14252\n",
      "[B] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7440, Brier: 0.0368, ECE: 0.0000\n",
      "  Combined Score: 0.13721\n",
      "\n",
      "--- Fold 3/5 학습 시작 ---\n",
      "\n",
      "[Fold 3] K-Fold Target Encoding (PK Stats) 생성...\n",
      "\n",
      "--- 모델 A (신규 자격) 학습 ---\n",
      "\n",
      "[A] CatBoost (Base) 학습 시작... (피처 98개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6379919\tbest: 0.6379919 (0)\ttotal: 20ms\tremaining: 59.9s\n",
      "bestTest = 0.7112259269\n",
      "bestIteration = 465\n",
      "Shrink model to first 466 iterations.\n",
      "\n",
      "[A] 단독 확률 보정 (Isotonic) 시작...\n",
      "[A] 비보정 단독 점수:\n",
      "  AUC: 0.7112, Brier: 0.0207, ECE: 0.0009\n",
      "  Combined Score: 0.14981\n",
      "[A] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7134, Brier: 0.0206, ECE: 0.0000\n",
      "  Combined Score: 0.14844\n",
      "\n",
      "--- 모델 B (자격 유지) 학습 ---\n",
      "\n",
      "[B] CatBoost (Base) 학습 시작... (피처 126개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6108274\tbest: 0.6108274 (0)\ttotal: 16.3ms\tremaining: 48.9s\n",
      "bestTest = 0.7311206162\n",
      "bestIteration = 80\n",
      "Shrink model to first 81 iterations.\n",
      "\n",
      "[B] 단독 확률 보정 (Isotonic) 시작...\n",
      "[B] 비보정 단독 점수:\n",
      "  AUC: 0.7311, Brier: 0.0381, ECE: 0.0249\n",
      "  Combined Score: 0.15019\n",
      "[B] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7339, Brier: 0.0364, ECE: 0.0000\n",
      "  Combined Score: 0.14216\n",
      "\n",
      "--- Fold 4/5 학습 시작 ---\n",
      "\n",
      "[Fold 4] K-Fold Target Encoding (PK Stats) 생성...\n",
      "\n",
      "--- 모델 A (신규 자격) 학습 ---\n",
      "\n",
      "[A] CatBoost (Base) 학습 시작... (피처 98개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6346480\tbest: 0.6346480 (0)\ttotal: 21.2ms\tremaining: 1m 3s\n",
      "bestTest = 0.7000406981\n",
      "bestIteration = 613\n",
      "Shrink model to first 614 iterations.\n",
      "\n",
      "[A] 단독 확률 보정 (Isotonic) 시작...\n",
      "[A] 비보정 단독 점수:\n",
      "  AUC: 0.7000, Brier: 0.0208, ECE: 0.0015\n",
      "  Combined Score: 0.15555\n",
      "[A] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7022, Brier: 0.0206, ECE: 0.0000\n",
      "  Combined Score: 0.15406\n",
      "\n",
      "--- 모델 B (자격 유지) 학습 ---\n",
      "\n",
      "[B] CatBoost (Base) 학습 시작... (피처 126개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6025567\tbest: 0.6025567 (0)\ttotal: 23.7ms\tremaining: 1m 11s\n",
      "bestTest = 0.733599335\n",
      "bestIteration = 113\n",
      "Shrink model to first 114 iterations.\n",
      "\n",
      "[B] 단독 확률 보정 (Isotonic) 시작...\n",
      "[B] 비보정 단독 점수:\n",
      "  AUC: 0.7336, Brier: 0.0374, ECE: 0.0191\n",
      "  Combined Score: 0.14734\n",
      "[B] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7365, Brier: 0.0364, ECE: 0.0000\n",
      "  Combined Score: 0.14084\n",
      "\n",
      "--- Fold 5/5 학습 시작 ---\n",
      "\n",
      "[Fold 5] K-Fold Target Encoding (PK Stats) 생성...\n",
      "\n",
      "--- 모델 A (신규 자격) 학습 ---\n",
      "\n",
      "[A] CatBoost (Base) 학습 시작... (피처 98개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6317332\tbest: 0.6317332 (0)\ttotal: 20.8ms\tremaining: 1m 2s\n",
      "bestTest = 0.697182864\n",
      "bestIteration = 332\n",
      "Shrink model to first 333 iterations.\n",
      "\n",
      "[A] 단독 확률 보정 (Isotonic) 시작...\n",
      "[A] 비보정 단독 점수:\n",
      "  AUC: 0.6972, Brier: 0.0209, ECE: 0.0012\n",
      "  Combined Score: 0.15693\n",
      "[A] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.6996, Brier: 0.0207, ECE: 0.0000\n",
      "  Combined Score: 0.15541\n",
      "\n",
      "--- 모델 B (자격 유지) 학습 ---\n",
      "\n",
      "[B] CatBoost (Base) 학습 시작... (피처 126개)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6114148\tbest: 0.6114148 (0)\ttotal: 17.9ms\tremaining: 53.6s\n",
      "bestTest = 0.7302920818\n",
      "bestIteration = 111\n",
      "Shrink model to first 112 iterations.\n",
      "\n",
      "[B] 단독 확률 보정 (Isotonic) 시작...\n",
      "[B] 비보정 단독 점수:\n",
      "  AUC: 0.7303, Brier: 0.0379, ECE: 0.0267\n",
      "  Combined Score: 0.15100\n",
      "[B] ★보정된 단독★ 최종 점수:\n",
      "  AUC: 0.7332, Brier: 0.0360, ECE: 0.0000\n",
      "  Combined Score: 0.14242\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 루프 실행\n",
    "all_pk_stats_folds = [] \n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} 학습 시작 ---\")\n",
    "    \n",
    "    train_idx = train_indices_list[fold]\n",
    "    val_idx = val_indices_list[fold]\n",
    "    \n",
    "    # 1. 전체 데이터에서 Train/Val 인덱스로 분리\n",
    "    train_df_fold = all_train_df.iloc[train_idx]\n",
    "    val_df_fold = all_train_df.iloc[val_idx]\n",
    "\n",
    "    # 2. [Leakage 수정] PK Stats를 'train_df_fold'로만 생성\n",
    "    print(f\"\\n[Fold {fold+1}] K-Fold Target Encoding (PK Stats) 생성...\")\n",
    "    agg_funcs = {\n",
    "        'Age_num': ['mean', 'min', 'max'], 'YearMonthIndex': ['mean', 'std', 'min', 'max'],\n",
    "        'A1_rt_mean': ['mean', 'std'], \n",
    "        'A4_acc_congruent': ['mean', 'std'], 'A4_acc_incongruent': ['mean', 'std'], 'A4_stroop_rt_cost': ['mean', 'std'],\n",
    "        'RiskScore': ['mean', 'std', 'max'], \n",
    "        'B1_change_acc': ['mean', 'std'], 'B1_nonchange_acc': ['mean', 'std'],\n",
    "        'B3_rt_mean': ['mean', 'std'],\n",
    "        'B4_flanker_acc_cost': ['mean', 'std'], 'B4_rt_mean': ['mean', 'std'],\n",
    "        'RiskScore_B': ['mean', 'std', 'max'], \n",
    "        'Test_id': ['count']\n",
    "    }\n",
    "\n",
    "    valid_agg_funcs = {col: funcs for col, funcs in agg_funcs.items() if col in train_df_fold.columns}\n",
    "    pk_stats_fold = train_df_fold.groupby('PrimaryKey').agg(valid_agg_funcs)\n",
    "    pk_stats_fold.columns = ['_'.join(col).strip() for col in pk_stats_fold.columns.values]\n",
    "    pk_stats_fold.rename(columns={'Test_id_count': 'pk_test_total_count'}, inplace=True)\n",
    "    \n",
    "    # [!!!!! KeyError 수정: 'Test_x' 사용 !!!!!]\n",
    "    pk_test_type_count_fold = train_df_fold.groupby('PrimaryKey')['Test_x'].value_counts().unstack(fill_value=0)\n",
    "    if 'A' not in pk_test_type_count_fold.columns:\n",
    "        pk_test_type_count_fold['A'] = 0\n",
    "    if 'B' not in pk_test_type_count_fold.columns:\n",
    "        pk_test_type_count_fold['B'] = 0\n",
    "    pk_test_type_count_fold = pk_test_type_count_fold[['A', 'B']]\n",
    "    pk_test_type_count_fold.columns = ['pk_test_A_count', 'pk_test_B_count']\n",
    "    pk_stats_fold = pk_stats_fold.join(pk_test_type_count_fold, how='left').reset_index()\n",
    "    \n",
    "    all_pk_stats_folds.append(pk_stats_fold) # Fold별 PK Stats 저장\n",
    "\n",
    "    # 3. A모델용 데이터 생성\n",
    "    # [!!!!! KeyError 수정: 'Test_x' 사용 !!!!!] => Test_x == 'A'인 샘플만 모아 Model A용.\n",
    "    X_train_A = train_df_fold[train_df_fold['Test_x'] == 'A'].copy()\n",
    "    y_train_A = X_train_A['Label'].values\n",
    "    X_val_A = val_df_fold[val_df_fold['Test_x'] == 'A'].copy()\n",
    "    y_val_A = X_val_A['Label'].values\n",
    "\n",
    "    # 4. B모델용 데이터 생성 => Test_x == 'B'인 샘플만 모아 Model B용.\n",
    "    X_train_B = train_df_fold[train_df_fold['Test_x'] == 'B'].copy()\n",
    "    y_train_B = X_train_B['Label'].values\n",
    "    X_val_B = val_df_fold[val_df_fold['Test_x'] == 'B'].copy()\n",
    "    y_val_B = X_val_B['Label'].values\n",
    "\n",
    "    # 5. 모델 A 학습 및 저장\n",
    "    print(\"\\n--- 모델 A (신규 자격) 학습 ---\")\n",
    "    cat_A, calibrator_A = train_model_A(X_train_A, y_train_A, X_val_A, y_val_A)\n",
    "    \n",
    "    joblib.dump(cat_A, os.path.join(MODEL_SAVE_DIR, f\"catboost_A_fold{fold}.pkl\"))\n",
    "    joblib.dump(calibrator_A, os.path.join(MODEL_SAVE_DIR, f\"calibrator_A_fold{fold}.pkl\"))\n",
    "\n",
    "    # 6. 모델 B 학습 및 저장 : B 샘플이 부족하거나 라벨이 단일 클래스면 학습 스킵.\n",
    "    print(\"\\n--- 모델 B (자격 유지) 학습 ---\")\n",
    "    if len(X_train_B) > 0 and len(X_val_B) > 0 and len(np.unique(y_train_B)) > 1:\n",
    "        cat_B, calibrator_B = train_model_B(X_train_B, y_train_B, X_val_B, y_val_B, pk_stats_fold)\n",
    "        \n",
    "        joblib.dump(cat_B, os.path.join(MODEL_SAVE_DIR, f\"catboost_B_fold{fold}.pkl\"))\n",
    "        joblib.dump(calibrator_B, os.path.join(MODEL_SAVE_DIR, f\"calibrator_B_fold{fold}.pkl\"))\n",
    "    else:\n",
    "        print(f\"[{fold+1} Fold] B모델 학습/검증 데이터가 부족하여 이 Fold를 건너뜁니다.\")\n",
    "        joblib.dump(None, os.path.join(MODEL_SAVE_DIR, f\"catboost_B_fold{fold}.pkl\"))\n",
    "        joblib.dump(None, os.path.join(MODEL_SAVE_DIR, f\"calibrator_B_fold{fold}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa6861a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] K-Fold PK Stats 병합...\n",
      "\n",
      "[INFO] '최종 보정' CatBoost 모델 10개 및 최종 통계 피처 1개 저장 완료:\n",
      "  ./model\\pk_stats_final.csv\n",
      "Big-Tech ML Engineer: 미션 완료. 이 11개의 파일로 `submit.zip`을 재구성하십시오.\n"
     ]
    }
   ],
   "source": [
    "# [신규] K-Fold로 생성된 PK Stats를 하나로 합침 (평균)\n",
    "print(\"\\n[INFO] K-Fold PK Stats 병합...\")\n",
    "if all_pk_stats_folds:\n",
    "    all_pk_stats_df = pd.concat(all_pk_stats_folds)\n",
    "    final_pk_stats = all_pk_stats_df.groupby('PrimaryKey').mean().reset_index()\n",
    "    final_pk_stats_path = os.path.join(MODEL_SAVE_DIR, \"pk_stats_final.csv\")\n",
    "    final_pk_stats.to_csv(final_pk_stats_path, index=False)\n",
    "else:\n",
    "    print(\"경고: 유효한 PK Stats가 생성되지 않았습니다. 빈 파일을 생성합니다.\")\n",
    "    pd.DataFrame().to_csv(os.path.join(MODEL_SAVE_DIR, \"pk_stats_final.csv\"), index=False)\n",
    "\n",
    "print(f\"\\n[INFO] '최종 보정' CatBoost 모델 10개 및 최종 통계 피처 1개 저장 완료:\")\n",
    "print(f\"  {final_pk_stats_path}\")\n",
    "print(\"Big-Tech ML Engineer: 미션 완료. 이 11개의 파일로 `submit.zip`을 재구성하십시오.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
