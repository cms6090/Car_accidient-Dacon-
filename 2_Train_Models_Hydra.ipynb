{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eea6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big-Tech ML Engineer: K-Fold + Leakage Fix + Domain Features ÏµúÏ¢Ö Ï†ÑÎûµ ÏãúÏûë.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import warnings\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra.utils import to_absolute_path\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646899fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"Ï†ÑÏ≤òÎ¶¨Îêú Î©îÏù∏ ÌîºÏ≤ò Î°úÎìú Ï§ë... (Îß§Ïö∞ Îπ†Î¶Ñ)\")\n",
    "    all_train_df = pd.read_feather(FEATURE_SAVE_PATH)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Í≤ΩÍ≥†: {e}\")\n",
    "    print(\"Î®ºÏ†Ä 1_Preprocess_v14.ipynbÎ•º Ïã§ÌñâÌïòÏó¨ all_train_data.featherÎ•º ÏÉùÏÑ±Ìï¥Ïïº Ìï©ÎãàÎã§.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6a242",
   "metadata": {},
   "source": [
    "## 1. Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e51d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÑÏ≤òÎ¶¨Îêú Î©îÏù∏ ÌîºÏ≤ò Î°úÎìú Ï§ë... (Îß§Ïö∞ Îπ†Î¶Ñ)\n",
      "Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å.\n"
     ]
    }
   ],
   "source": [
    "# ECE Í≥ÑÏÇ∞Í∏∞\n",
    "def expected_calibration_error(y_true, y_prob, n_bins=10):\n",
    "    if len(y_true) == 0 or len(y_prob) == 0:\n",
    "        return 0.0\n",
    "    y_prob = np.nan_to_num(y_prob, nan=0.0)\n",
    "\n",
    "    df = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob})\n",
    "\n",
    "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_edges[0] = -0.001\n",
    "    bin_edges[-1] = 1.001\n",
    "\n",
    "    df['y_prob'] = np.clip(df['y_prob'], 0, 1)\n",
    "    df['bin'] = pd.cut(df['y_prob'], bins=bin_edges, right=True)\n",
    "\n",
    "    bin_stats = df.groupby('bin', observed=True).agg(\n",
    "        bin_total=('y_prob', 'count'),\n",
    "        prob_true=('y_true', 'mean'),\n",
    "        prob_pred=('y_prob', 'mean')\n",
    "    )\n",
    "\n",
    "    non_empty_bins = bin_stats[bin_stats['bin_total'] > 0]\n",
    "    if len(non_empty_bins) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    bin_weights = non_empty_bins['bin_total'] / len(y_prob)\n",
    "    prob_true = non_empty_bins['prob_true']\n",
    "    prob_pred = non_empty_bins['prob_pred']\n",
    "\n",
    "    ece = np.sum(bin_weights * np.abs(prob_true - prob_pred))\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏµúÏ¢Ö Ï†êÏàò Í≥ÑÏÇ∞Í∏∞\n",
    "def combined_score(y_true, y_prob):\n",
    "    if len(y_true) == 0 or len(y_prob) == 0 or np.sum(y_true) == 0 or np.sum(y_true) == len(y_true):\n",
    "        print(\"  AUC: N/A (Îã®Ïùº ÌÅ¥ÎûòÏä§), Brier: N/A, ECE: N/A (No data)\")\n",
    "        return 1.0\n",
    "\n",
    "    y_prob = np.nan_to_num(y_prob, nan=0.0)\n",
    "\n",
    "    mean_auc = roc_auc_score(y_true, y_prob)\n",
    "    mean_brier = mean_squared_error(y_true, y_prob)\n",
    "    mean_ece = expected_calibration_error(y_true, y_prob)\n",
    "    score = 0.5 * (1 - mean_auc) + 0.25 * mean_brier + 0.25 * mean_ece\n",
    "\n",
    "    print(f\"  AUC: {mean_auc:.4f}, Brier: {mean_brier:.4f}, ECE: {mean_ece:.4f}\")\n",
    "    print(f\"  Combined Score: {score:.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3688d8",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cfg, X_train, y_train, X_val, y_val, pk_stats_fold=None, group_label=\"A\"):\n",
    "    cat_features = list(cfg.cat_features)\n",
    "    drop_cols = set(cfg.drop_cols_train)\n",
    "\n",
    "    # leakage-free pk_stats_fold (BÎ™®Îç∏ÏóêÎßå ÏÇ¨Ïö©)\n",
    "    if pk_stats_fold is not None:\n",
    "        X_train = X_train.merge(pk_stats_fold, on=\"PrimaryKey\", how=\"left\")\n",
    "        X_val = X_val.merge(pk_stats_fold, on=\"PrimaryKey\", how=\"left\")\n",
    "\n",
    "    # numeric feature ÏÑ†ÌÉù\n",
    "    numeric_cols = [\n",
    "        c for c in X_train.columns\n",
    "        if c not in cat_features and c not in drop_cols\n",
    "    ]\n",
    "    numeric_cols = list(set(numeric_cols) & set(X_val.columns))\n",
    "\n",
    "    cb_X_train = X_train[numeric_cols + cat_features].copy()\n",
    "    cb_X_val = X_val[numeric_cols + cat_features].copy()\n",
    "\n",
    "    for col in cat_features:\n",
    "        cb_X_train[col] = cb_X_train[col].fillna(\"nan\").astype(str)\n",
    "        cb_X_val[col] = cb_X_val[col].fillna(\"nan\").astype(str)\n",
    "\n",
    "    cat_idx = [\n",
    "        cb_X_train.columns.get_loc(c)\n",
    "        for c in cat_features\n",
    "        if c in cb_X_train.columns\n",
    "    ]\n",
    "\n",
    "    # Ïñ¥Îñ§ ÏÑ§Ï†ï Ïì∏ÏßÄ Í≤∞Ï†ï (A or B)\n",
    "    mcfg = cfg.modelA if group_label.startswith(\"A\") else cfg.modelB\n",
    "\n",
    "    print(f\"\\n[{group_label}] CatBoost ÌïôÏäµ ÏãúÏûë ({len(cb_X_train.columns)} features)\")\n",
    "    model = cb.CatBoostClassifier(\n",
    "        iterations=int(mcfg.iterations),\n",
    "        learning_rate=float(mcfg.learning_rate),\n",
    "        depth=int(mcfg.depth),\n",
    "        l2_leaf_reg=float(mcfg.l2_leaf_reg),\n",
    "        loss_function=str(mcfg.loss_function),\n",
    "        eval_metric=str(mcfg.eval_metric),\n",
    "        random_seed=42,\n",
    "        thread_count=int(mcfg.thread_count),\n",
    "        early_stopping_rounds=int(mcfg.early_stopping_rounds),\n",
    "        verbose=1000,\n",
    "        task_type=str(mcfg.task_type),\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        cb_X_train,\n",
    "        y_train,\n",
    "        eval_set=[(cb_X_val, y_val)],\n",
    "        cat_features=cat_idx,\n",
    "    )\n",
    "\n",
    "    # Calibration with Isotonic Regression\n",
    "    pred_uncal = model.predict_proba(cb_X_val)[:, 1]\n",
    "    print(f\"[{group_label}] ÎπÑÎ≥¥Ï†ï Ï†êÏàò:\")\n",
    "    _ = combined_score(y_val, pred_uncal, cfg.metric.n_bins_ece)\n",
    "\n",
    "    calibrator = IsotonicRegression(y_min=0, y_max=1, out_of_bounds=\"clip\")\n",
    "    calibrator.fit(pred_uncal, y_val)\n",
    "\n",
    "    pred_cal = calibrator.predict(pred_uncal)\n",
    "    print(f\"[{group_label}] ‚òÖÎ≥¥Ï†ï ÌõÑ Ï†êÏàò‚òÖ\")\n",
    "    score = combined_score(y_val, pred_cal, cfg.metric.n_bins_ece)\n",
    "\n",
    "    return model, calibrator, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e867249",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea116720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] K-Fold ÍµêÏ∞® Í≤ÄÏ¶ù Î∂ÑÎ¶¨ ÏãúÏûë...\n",
      "5-Fold Î∂ÑÎ¶¨ ÏôÑÎ£å.\n"
     ]
    }
   ],
   "source": [
    "@hydra.main(version_base=None, config_path=\"conf\", config_name=\"config\")\n",
    "def main(cfg: DictConfig):\n",
    "    # üîë OptunaÍ∞Ä modelA.*, modelB.*Î•º override Ìï† Ïàò ÏûàÎèÑÎ°ù struct Ïû†Í∏à Ìï¥Ï†ú\n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "    if \"modelA\" in cfg:\n",
    "        OmegaConf.set_struct(cfg.modelA, False)\n",
    "    if \"modelB\" in cfg:\n",
    "        OmegaConf.set_struct(cfg.modelB, False)\n",
    "\n",
    "    print(\"Big-Tech ML Engineer: Hydra Í∏∞Î∞ò K-Fold ÌïôÏäµ/Î≥¥Ï†ï + Í≤∞Í≥º Î°úÍπÖ ÏãúÏûë\")\n",
    "\n",
    "    base_dir = to_absolute_path(cfg.general.base_dir)\n",
    "    model_dir = to_absolute_path(cfg.general.model_save_dir)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Î°úÍ∑∏ ÎîîÎ†âÌÜ†Î¶¨\n",
    "    log_dir = os.path.join(model_dir, \"hydra_logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(log_dir, f\"run_{run_id}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    # Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "    feature_path = os.path.join(base_dir, cfg.general.feature_file)\n",
    "    all_train_df = pd.read_feather(feature_path)\n",
    "    all_train_df[\"Label\"] = all_train_df[\"Label\"].fillna(0)\n",
    "    print(\"Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å:\", all_train_df.shape)\n",
    "\n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=cfg.cv.n_splits,\n",
    "        shuffle=cfg.cv.shuffle,\n",
    "        random_state=cfg.cv.random_state,\n",
    "    )\n",
    "\n",
    "    fold_results = []\n",
    "    all_pk_stats_folds = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(\n",
    "        skf.split(all_train_df, all_train_df[\"Label\"])\n",
    "    ):\n",
    "        print(f\"\\n========== Fold {fold + 1}/{cfg.cv.n_splits} ==========\")\n",
    "\n",
    "        train_df = all_train_df.iloc[train_idx].copy()\n",
    "        val_df = all_train_df.iloc[val_idx].copy()\n",
    "\n",
    "        # ----- PK Stats (BÎ™®Îç∏ Ïö©) -----\n",
    "        agg_funcs = {\n",
    "            \"Age_num\": [\"mean\", \"min\", \"max\"],\n",
    "            \"RiskScore\": [\"mean\", \"std\", \"max\"],\n",
    "            \"Test_id\": [\"count\"],\n",
    "        }\n",
    "        valid_agg = {c: fs for c, fs in agg_funcs.items() if c in train_df.columns}\n",
    "\n",
    "        pk_stats = train_df.groupby(\"PrimaryKey\").agg(valid_agg)\n",
    "        pk_stats.columns = [\"_\".join(col).strip() for col in pk_stats.columns.values]\n",
    "        if \"Test_id_count\" in pk_stats.columns:\n",
    "            pk_stats.rename(\n",
    "                columns={\"Test_id_count\": \"pk_test_total_count\"}, inplace=True\n",
    "            )\n",
    "        pk_stats.reset_index(inplace=True)\n",
    "        all_pk_stats_folds.append(pk_stats)\n",
    "\n",
    "        # ----- A/B Î∂ÑÎ¶¨ -----\n",
    "        X_train_A = train_df[train_df[\"Test_x\"] == \"A\"]\n",
    "        y_train_A = X_train_A[\"Label\"].values\n",
    "        X_val_A = val_df[val_df[\"Test_x\"] == \"A\"]\n",
    "        y_val_A = X_val_A[\"Label\"].values\n",
    "\n",
    "        X_train_B = train_df[train_df[\"Test_x\"] == \"B\"]\n",
    "        y_train_B = X_train_B[\"Label\"].values\n",
    "        X_val_B = val_df[val_df[\"Test_x\"] == \"B\"]\n",
    "        y_val_B = X_val_B[\"Label\"].values\n",
    "\n",
    "        # ----- Model A -----\n",
    "        model_A, calib_A, score_A = train_model(\n",
    "            cfg,\n",
    "            X_train_A,\n",
    "            y_train_A,\n",
    "            X_val_A,\n",
    "            y_val_A,\n",
    "            pk_stats_fold=None,\n",
    "            group_label=f\"A_fold{fold+1}\",\n",
    "        )\n",
    "        joblib.dump(model_A, os.path.join(model_dir, f\"catboost_A_fold{fold}.pkl\"))\n",
    "        joblib.dump(calib_A, os.path.join(model_dir, f\"calibrator_A_fold{fold}.pkl\"))\n",
    "\n",
    "        # ----- Model B -----\n",
    "        if (\n",
    "            len(X_train_B) > 0\n",
    "            and len(X_val_B) > 0\n",
    "            and len(np.unique(y_train_B)) > 1\n",
    "        ):\n",
    "            model_B, calib_B, score_B = train_model(\n",
    "                cfg,\n",
    "                X_train_B,\n",
    "                y_train_B,\n",
    "                X_val_B,\n",
    "                y_val_B,\n",
    "                pk_stats_fold=pk_stats,\n",
    "                group_label=f\"B_fold{fold+1}\",\n",
    "            )\n",
    "            joblib.dump(model_B, os.path.join(model_dir, f\"catboost_B_fold{fold}.pkl\"))\n",
    "            joblib.dump(\n",
    "                calib_B, os.path.join(model_dir, f\"calibrator_B_fold{fold}.pkl\")\n",
    "            )\n",
    "        else:\n",
    "            score_B = np.nan\n",
    "            print(f\"[Fold {fold+1}] B Î™®Îç∏ Ïä§ÌÇµ (Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°± or Îã®Ïùº ÌÅ¥ÎûòÏä§)\")\n",
    "\n",
    "        fold_mean = np.nanmean([score_A, score_B])\n",
    "        fold_results.append(\n",
    "            {\n",
    "                \"fold\": fold + 1,\n",
    "                \"score_A\": score_A,\n",
    "                \"score_B\": score_B,\n",
    "                \"combined_mean\": fold_mean,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # ----- Fold Í≤∞Í≥º Ï†ïÎ¶¨ -----\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    mean_score = np.nanmean(results_df[\"combined_mean\"])\n",
    "    results_df[\"overall_mean\"] = mean_score\n",
    "\n",
    "    # ÏÑ§Ï†ï + Í≤∞Í≥º ÏöîÏïΩ\n",
    "    param_summary = {\n",
    "        \"run_id\": run_id,\n",
    "        \"mean_score\": mean_score,\n",
    "    }\n",
    "    if \"modelA\" in cfg:\n",
    "        for k, v in cfg.modelA.items():\n",
    "            param_summary[f\"modelA.{k}\"] = v\n",
    "    if \"modelB\" in cfg:\n",
    "        for k, v in cfg.modelB.items():\n",
    "            param_summary[f\"modelB.{k}\"] = v\n",
    "\n",
    "    # CSV Ï†ÄÏû•\n",
    "    results_df.to_csv(\n",
    "        os.path.join(run_dir, \"training_results.csv\"), index=False, encoding=\"utf-8-sig\"\n",
    "    )\n",
    "    pd.DataFrame([param_summary]).to_csv(\n",
    "        os.path.join(run_dir, \"config_summary.csv\"),\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "    )\n",
    "    print(f\"\\n[INFO] FoldÎ≥Ñ Ï†êÏàò Î∞è ÏÑ§Ï†ï Ï†ÄÏû• ÏôÑÎ£å ‚Üí {run_dir}\")\n",
    "\n",
    "    # best_result.csv Í∞±Ïã†\n",
    "    best_path = os.path.join(log_dir, \"best_result.csv\")\n",
    "    if os.path.exists(best_path):\n",
    "        prev = pd.read_csv(best_path)\n",
    "        best_prev = float(prev.iloc[0][\"mean_score\"])\n",
    "    else:\n",
    "        best_prev = np.inf\n",
    "\n",
    "    if mean_score < best_prev:\n",
    "        pd.DataFrame([param_summary]).to_csv(\n",
    "            best_path, index=False, encoding=\"utf-8-sig\"\n",
    "        )\n",
    "        print(f\"üèÜ ÏÉà ÏµúÍ≥† Ï†êÏàò Í∞±Ïã†! ({mean_score:.5f}) ‚Üí best_result.csv ÏóÖÎç∞Ïù¥Ìä∏\")\n",
    "    else:\n",
    "        print(f\"ÌòÑÏû¨ Ï†êÏàò {mean_score:.5f} (Í∏∞Ï°¥ ÏµúÍ≥† {best_prev:.5f})\")\n",
    "\n",
    "    print(\"\\nBig-Tech ML Engineer: Hydra run Ï¢ÖÎ£å\")\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec79837",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
